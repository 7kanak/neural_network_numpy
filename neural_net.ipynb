{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNet():\n",
    "    def __init__(self,feat):\n",
    "        np.random.seed(2)  \n",
    "        self.weights = {} \n",
    "        self.num_layers = 1  \n",
    "        self.prev_layer = feat\n",
    "        self.activation_values = {}\n",
    "        self.delta = {}\n",
    "        self.partial_deriv = {}\n",
    "        \n",
    "    def add_layer(self, num,bias=True):\n",
    "        self.weights[self.num_layers] =2*(np.random.rand(self.prev_layer+1,num))-1\n",
    "        self.num_layers += 1\n",
    "        self.prev_layer=num\n",
    "    \n",
    "    def add_bias(self,X):\n",
    "        bias=np.ones((X.shape[0],1))\n",
    "        data=np.hstack((bias,X))\n",
    "        return data\n",
    "    \n",
    "    def feed_forward(self,X):\n",
    "        self.activation_values[1] = self.add_bias(X)\n",
    "        for layer in range(1,self.num_layers):\n",
    "            acti = self.sigmoid(np.dot(self.activation_values[layer],self.weights[layer]))\n",
    "            if layer == self.num_layers-1:\n",
    "                self.activation_values[layer+1] = acti\n",
    "            else:\n",
    "                self.activation_values[layer+1] = self.add_bias(acti)\n",
    "    \n",
    "    def test(self,y,y_label):\n",
    "        new = {}\n",
    "        new[1] = self.add_bias(y)\n",
    "        for layer in range(1,self.num_layers):\n",
    "            acti = self.sigmoid(np.dot(new[layer],self.weights[layer]))\n",
    "            if layer == self.num_layers-1:\n",
    "                new[layer+1] = acti\n",
    "            else:\n",
    "                new[layer+1] = self.add_bias(acti)\n",
    "        return new[self.num_layers],np.average((new[self.num_layers]>0.5).astype(int)==y_label)\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def cost_fn(self,label):\n",
    "        activation=self.activation_values[self.num_layers]\n",
    "        return -1*np.average(np.log(activation)*label + np.log(1-activation)*(1-label))\n",
    "    \n",
    "    def accuracy(self,labels):\n",
    "        return np.average((self.activation_values[self.num_layers]>0.5).astype(int)==labels)\n",
    "        \n",
    "    \n",
    "    def sigmoid_der(self,x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def back_propagation(self,label,lbd,train_size):\n",
    "        self.delta[self.num_layers] = self.activation_values[self.num_layers] - label\n",
    "        for layer in reversed(range(2, self.num_layers)):\n",
    "            tmp = (np.dot(self.delta[layer+1],self.weights[layer].T)*self.sigmoid_der(self.activation_values[layer]))\n",
    "            self.delta[layer] = tmp[:,1:]\n",
    "\n",
    "        for layer in range(1, self.num_layers):\n",
    "            theta=self.weights[layer]\n",
    "            self.partial_deriv[layer] = ((np.dot(self.activation_values[layer].T,self.delta[layer+1])))#+(lbd*theta))/train_size\n",
    "    \n",
    "    def gradient_descent(self,learning_rate):\n",
    "        for layer in range(1, self.num_layers):\n",
    "            self.weights[layer] = self.weights[layer]-learning_rate*self.partial_deriv[layer]\n",
    "    \n",
    "    def train(self,data,label,train_size,learning_rate=0.1,error_limit=0.1,max_epochs=10000,lbd=0):\n",
    "        i=0\n",
    "        while True:\n",
    "            i=i+1\n",
    "            self.feed_forward(data)\n",
    "            self.back_propagation(label,train_size,lbd)\n",
    "            error= self.cost_fn(label)\n",
    "            self.gradient_descent(learning_rate)\n",
    "            accuracy = self.accuracy(label)\n",
    "            if (error<error_limit) | (i==max_epochs):\n",
    "                return error,i#,self.activation_values[self.num_layers],self.accuracy(label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mf(a):\n",
    "    return (a[0]+a[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = 100*(np.random.random((100,2)))+1\n",
    "y = ((np.apply_along_axis(mf,1,X))>85).astype(int)\n",
    "y=y.reshape(100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y=np.array([[0],[1],[1],[0]])\n",
    "nn=NeuralNet(2)\n",
    "nn.add_layer(5)\n",
    "nn.add_layer(3)\n",
    "nn.add_layer(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 (0.6931115082531234, 10000)\n",
      "0.003 (0.69308314666317961, 10000)\n",
      "0.01 (0.69289095101380616, 10000)\n",
      "0.03 (0.099673728143862994, 8929)\n",
      "0.1 (0.098350091821930843, 2711)\n",
      "0.3 (0.075565262216721343, 1026)\n",
      "1 (0.4774613488987316, 10000)\n",
      "3 (1.3611930400380996, 10000)\n",
      "10 (4.9995947866543746, 10000)\n"
     ]
    }
   ],
   "source": [
    "for i in [0.001,0.003,0.01,0.03,0.1,0.3,1,3,10]:\n",
    "    nn=NeuralNet(2)\n",
    "    nn.add_layer(20)\n",
    "    nn.add_layer(10)\n",
    "    nn.add_layer(20)\n",
    "    nn.add_layer(10)\n",
    "    nn.add_layer(20)\n",
    "    nn.add_layer(1)\n",
    "    print i,nn.train(X,y,4,error_limit=0.1,learning_rate=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = 5*(np.random.random((10,1)))+1\n",
    "test_label = ((np.apply_along_axis(mf,1,test_set))>15).astype(int).reshape(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.03569607],\n",
       "        [ 0.91012668],\n",
       "        [ 0.05795095],\n",
       "        [ 0.03571448],\n",
       "        [ 0.91016567],\n",
       "        [ 0.91015165],\n",
       "        [ 0.90213275],\n",
       "        [ 0.03574024],\n",
       "        [ 0.9084172 ],\n",
       "        [ 0.03579163]]), 1.0)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.test(test_set,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([[ 27.11711866,  -1.23640219,  -0.24969911,  -0.17965665,\n",
       "          -0.47373616,  12.80500818,  -0.89779544,  -0.88653633,\n",
       "          -0.78363874],\n",
       "        [  1.06367457,  -0.99975702,  -5.54792755,  -1.8439967 ,\n",
       "          -5.08533565,   1.35085649,   3.02354192,   4.65375953,\n",
       "           3.57086661],\n",
       "        [ -3.65153391,  -1.74705688,  -5.53135405,  -1.85876602,\n",
       "          -5.10723617,  -1.39030429,   2.03329033,   4.25741813,\n",
       "           3.12220041]]),\n",
       " 2: array([[ -3.51431816,  -1.55297456,  -1.03415756,  -2.63544696,\n",
       "          -2.48307469,  -1.10781592],\n",
       "        [ -4.007936  ,  -0.31526887,  -5.31423777,  -0.82818064,\n",
       "          -1.09393145, -11.62829599],\n",
       "        [  0.32796078,   0.83413657,  -0.12917808,   0.48573145,\n",
       "          -0.29226829,  -0.23834581],\n",
       "        [ -0.73609091,  -0.11281773,   0.67616488,   0.0251413 ,\n",
       "           0.58535812,  -0.31601318],\n",
       "        [ -0.75828731,  -0.30117223,   0.9395543 ,  -0.30226743,\n",
       "          -0.74479342,  -0.61096565],\n",
       "        [ -0.79343976,   0.94168606,   0.78966859,   0.56555908,\n",
       "           0.19837015,   0.52275444],\n",
       "        [ -1.25423735,  -6.76915318,   1.13197019,  -0.89617836,\n",
       "           0.03531214,   4.77208292],\n",
       "        [ -2.48421364,   0.5864224 ,  -1.20363882,  -0.86939169,\n",
       "          -2.07962816,   0.74548449],\n",
       "        [ -2.2195547 ,  -1.05755152,  -1.36204173,  -1.7756313 ,\n",
       "          -2.25644555,  -1.03251871],\n",
       "        [ -2.9571468 ,  -0.32562712,  -1.1584765 ,  -2.06400623,\n",
       "          -1.6682222 ,  -0.98321489]]),\n",
       " 3: array([[ 1.77544595],\n",
       "        [ 0.14832228],\n",
       "        [-0.06038985],\n",
       "        [ 0.8066299 ],\n",
       "        [ 0.97129213],\n",
       "        [ 0.16035891],\n",
       "        [ 3.72890655]])}"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.]])"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((5,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
