{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLearning():\n",
    "    def __init__(self,X,label,learning_rate,lbd=0,batch_size = None):\n",
    "        np.random.seed(2)\n",
    "        np.seterr(all='raise')\n",
    "        self.m = X.shape[1]\n",
    "        self.n = {}\n",
    "        self.prev_layer = X.shape[0]\n",
    "        self.weights = {}\n",
    "        self.bias = {}\n",
    "        self.z = {}\n",
    "        self.a = {}\n",
    "        self.num_layers=0\n",
    "        self.fn = {}\n",
    "        self.da = {}\n",
    "        self.dw = {}\n",
    "        self.db = {}\n",
    "        self.vdw = {}\n",
    "        self.vdb = {}\n",
    "        self.sdw = {}\n",
    "        self.sdb = {}\n",
    "        #self.vdw[1] = 0\n",
    "        #self.vdb[1] = 0\n",
    "        #self.a[0] = X\n",
    "        self.alpha0 = learning_rate\n",
    "        self.alpha = learning_rate\n",
    "        self.y = label\n",
    "        self.lbd = lbd\n",
    "        self.keep_prob = {}\n",
    "        self.drop_out = {}\n",
    "        self.X = X\n",
    "        self.batch_size = batch_size\n",
    "        self.mbeta = 1\n",
    "        self.rmsbeta = 1\n",
    "        \n",
    "    def add_layer(self,neurons,acti_fn='sigmoid',c=1.0,keep_prob=1.0):\n",
    "        if acti_fn=='relu':\n",
    "            c=2.0\n",
    "        self.weights[self.num_layers+1] = np.random.randn(neurons,self.prev_layer)*np.sqrt(c/self.prev_layer)\n",
    "        #self.weights[self.num_layers+1] = 2*(np.random.rand(neurons,self.prev_layer))-1\n",
    "        self.bias[self.num_layers+1] = np.random.random((neurons,1))\n",
    "        \n",
    "        self.vdw[self.num_layers+1] = np.zeros((neurons,self.prev_layer))\n",
    "        self.vdb[self.num_layers+1] = np.zeros((neurons,1))\n",
    "        self.sdw[self.num_layers+1] = np.zeros((neurons,self.prev_layer))\n",
    "        self.sdb[self.num_layers+1] = np.zeros((neurons,1))\n",
    "        \n",
    "        self.num_layers+=1\n",
    "        self.fn[self.num_layers] = acti_fn\n",
    "        self.keep_prob[self.num_layers] = keep_prob\n",
    "        self.prev_layer=neurons\n",
    "        \n",
    "        \n",
    "    def fit(self,test):\n",
    "        a_tmp = test\n",
    "        for layer in range(1,self.num_layers+1):\n",
    "            z_tmp = np.dot(self.weights[layer],a_tmp) + self.bias[layer]\n",
    "            a_tmp = self.activation_function(z_tmp,self.fn[layer])\n",
    "        return a_tmp\n",
    "    \n",
    "    def feed_forward(self,X):\n",
    "        self.a[0] = self.X\n",
    "        for layer in range(1,self.num_layers+1):\n",
    "            self.z[layer] = np.dot(self.weights[layer],self.a[layer-1]) + self.bias[layer]\n",
    "            self.a[layer] = self.activation_function(self.z[layer],self.fn[layer])\n",
    "            if self.keep_prob[layer]!=1:\n",
    "                self.drop_out[layer] = np.random.rand(self.a[layer].shape[0],self.a[layer].shape[1])<self.keep_prob[layer]\n",
    "                self.a[layer] = np.multiply(self.drop_out[layer],self.a[layer])\n",
    "                self.a[layer] /=self.keep_prob[layer]\n",
    "            else:\n",
    "                self.drop_out[layer]=1\n",
    "    \n",
    "    def activation_function(self,x,acti_fn):\n",
    "        if acti_fn == 'tanh':\n",
    "            return (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
    "        if acti_fn == 'relu':\n",
    "            return np.maximum(0.01*x,x)\n",
    "        if acti_fn == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "        \n",
    "    def back_pass(self):\n",
    "        #self.da[self.num_layers] = -1*(self.y/self.a[self.num_layers])+(1-self.y)/(1-self.a[self.num_layers])\n",
    "        try:\n",
    "            self.da[self.num_layers] = (self.y-self.a[self.num_layers])/(self.a[self.num_layers]**2-1) \n",
    "        except:\n",
    "            self.da[self.num_layers] = (self.y-self.a[self.num_layers])/(self.a[self.num_layers]**2-1+np.power(0.10,-8)) \n",
    "        for layer in reversed(range(1,self.num_layers+1)):\n",
    "            tmp = self.da[layer]*self.derivative_fn(self.a[layer],self.fn[layer])\n",
    "            self.dw[layer] = (np.dot(tmp,(self.a[layer-1]).T))/self.m + (self.lbd*self.weights[layer])/(self.m+0.0)\n",
    "            self.db[layer] = (np.sum(tmp,axis=1,keepdims=True))/self.m\n",
    "            self.da[layer-1] = np.dot((self.weights[layer]).T,tmp)\n",
    "            if layer>1:\n",
    "                self.da[layer-1] = self.drop_out[layer-1]*self.da[layer-1]\n",
    "                self.da[layer-1]/=self.keep_prob[layer-1]\n",
    "    \n",
    "    def derivative_fn(self,x,acti_fn):\n",
    "        #x = self.activation_function(x,acti_fn)\n",
    "        if acti_fn == 'tanh':\n",
    "            return 1-x**2\n",
    "        if acti_fn == 'relu':\n",
    "            return np.where(x<=0,0.01,1)\n",
    "        if acti_fn == 'sigmoid':\n",
    "            return x * (1 - x)\n",
    "    \n",
    "    def gradient_descent(self):\n",
    "        for layer in range(1,self.num_layers+1):\n",
    "            self.weights[layer] = self.weights[layer] -self.alpha*self.dw[layer]\n",
    "            self.bias[layer] = self.bias[layer] - self.alpha*self.db[layer]\n",
    "    \n",
    "    def momentum(self):\n",
    "        for layer in range(1,self.num_layers+1):\n",
    "            \n",
    "            self.vdw[layer] = self.mbeta * self.vdw[layer] + (1-self.mbeta)*self.dw[layer]\n",
    "            self.vdb[layer] = self.mbeta * self.vdb[layer] + (1-self.mbeta)*self.db[layer]\n",
    "            \n",
    "            self.weights[layer] = self.weights[layer] -self.alpha*self.vdw[layer]\n",
    "            self.bias[layer] = self.bias[layer] - self.alpha*self.vdb[layer]\n",
    "            \n",
    "    def rms_prop(self,rms_epsilon):\n",
    "        print t\n",
    "        for layer in range(1,self.num_layers+1):\n",
    "            \n",
    "            self.sdw[layer] = self.rmsbeta * self.sdw[layer] + (1-self.rmsbeta)*(self.dw[layer]**2)\n",
    "            self.sdb[layer] = self.rmsbeta * self.sdb[layer] + (1-self.rmsbeta)*(self.db[layer]**2)\n",
    "            \n",
    "            self.weights[layer] = self.weights[layer] - self.alpha*(self.dw[layer]/np.sqrt(self.sdw[layer] + rms_epsilon))\n",
    "            self.bias[layer] = self.bias[layer] - self.alpha*(self.db[layer]/np.sqrt(self.sdb[layer] + rms_epsilon))\n",
    "         \n",
    "    def adam(self,rms_epsilon):\n",
    "        for layer in range(1,self.num_layers+1):\n",
    "            self.vdw[layer] = self.mbeta * self.vdw[layer] + (1-self.mbeta)*self.dw[layer]\n",
    "            self.vdb[layer] = self.mbeta * self.vdb[layer] + (1-self.mbeta)*self.db[layer]\n",
    "            \n",
    "            self.sdw[layer] = self.rmsbeta * self.sdw[layer] + (1-self.rmsbeta)*(self.dw[layer]**2)\n",
    "            self.sdb[layer] = self.rmsbeta * self.sdb[layer] + (1-self.rmsbeta)*(self.db[layer]**2)\n",
    "           \n",
    "            self.weights[layer] = self.weights[layer] - self.alpha*(self.vdw[layer]/np.sqrt(self.sdw[layer] + rms_epsilon))\n",
    "            self.bias[layer] = self.bias[layer] - self.alpha*(self.vdb[layer]/np.sqrt(self.sdb[layer] + rms_epsilon))\n",
    "            \n",
    "    def cost_fn(self):\n",
    "        activation=self.a[self.num_layers]\n",
    "        reg_error = 0\n",
    "        for layer in range(1,self.num_layers+1):\n",
    "            reg_error += (np.linalg.norm(self.weights[layer]))**2\n",
    "        reg_error = (reg_error*self.lbd)/(self.m+0.0)\n",
    "        try:\n",
    "            result = (-1*np.average(np.log(activation)*self.y + np.log(1-activation)*(1-self.y)))+reg_error,np.sum((activation>0.5).astype(int)==self.y)/(self.m+0.0)\n",
    "        except:\n",
    "            activation = np.where(activation==0,np.power(0.10,8),activation)\n",
    "            activation = np.where(activation==1,1-np.power(0.10,8),activation)\n",
    "            result = (-1*np.average(np.log(activation)*self.y + np.log(1-activation)*(1-self.y)))+reg_error,np.sum((activation>0.5).astype(int)==self.y)/(self.m+0.0)\n",
    "        return result\n",
    "    \n",
    "    def train(self):\n",
    "        for i in range(0, 30000):\n",
    "            self.feed_forward(self.X)\n",
    "            self.back_pass()\n",
    "            self.gradient_descent()\n",
    "            print self.cost_fn()\n",
    "            if self.cost_fn()[0]<0.05:\n",
    "                print i,self.cost_fn()\n",
    "                break\n",
    "                \n",
    "    def batch_train(self,batch_size=None,optimization_algo=\"gradient_descent\",momentum_beta=1,rmsbeta=1,rms_epsilon=np.power(0.10,-8),decay=False):\n",
    "        self.mbeta = momentum_beta\n",
    "        self.rmsbeta = rmsbeta\n",
    "        if batch_size is None:\n",
    "                batch_size = self.m\n",
    "        nb = int(np.ceil((self.m+0.0)/batch_size))\n",
    "        for i in range(0, 30000):\n",
    "            if decay == True:\n",
    "                self.alpha = np.power(0.95,i)*self.alpha0 + 0.0001\n",
    "            for t in range(0,nb):\n",
    "                X_b = X[:,batch_size*t:batch_size*(t+1)]\n",
    "                self.feed_forward(X_b)\n",
    "                self.back_pass()\n",
    "                self.gradient_descent()\n",
    "                if optimization_algo=='momentum':\n",
    "                    self.momentum()\n",
    "                print i,self.cost_fn()\n",
    "                \n",
    "            if self.cost_fn()[0]<0.1:\n",
    "                print i,self.cost_fn()\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mf(a):\n",
    "    return (a[0]+a[1])\n",
    "X = 100*(np.random.random((2,10000)))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = ((np.apply_along_axis(mf,0,X))>110).astype(int).reshape(1,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.84594273312056989, 0.57699999999999996)\n",
      "0 (2.1695507714942792, 0.42299999999999999)\n",
      "0 (0.77886633966704844, 0.57699999999999996)\n",
      "0 (0.70875447011278669, 0.46289999999999998)\n",
      "0 (0.68911238860002166, 0.56069999999999998)\n",
      "0 (0.67873211530089816, 0.57699999999999996)\n",
      "0 (0.67517356452243638, 0.57699999999999996)\n",
      "0 (0.66985378994076128, 0.57699999999999996)\n",
      "0 (0.66098928651342381, 0.57699999999999996)\n",
      "0 (0.64490254211882969, 0.57699999999999996)\n",
      "0 (0.64181911597813812, 0.57699999999999996)\n",
      "0 (0.66563522715214718, 0.62970000000000004)\n",
      "0 (0.77223346894155287, 0.57699999999999996)\n",
      "0 (0.65877721542520318, 0.63600000000000001)\n",
      "0 (0.62953983195053553, 0.72099999999999997)\n",
      "0 (0.64571781916853743, 0.71099999999999997)\n",
      "0 (0.64731580496621943, 0.62170000000000003)\n",
      "0 (0.80645181623258433, 0.65100000000000002)\n",
      "0 (0.66816724468068478, 0.54110000000000003)\n",
      "0 (0.63095467098527525, 0.67269999999999996)\n",
      "0 (0.63432270708155081, 0.72750000000000004)\n",
      "0 (0.62119255459087064, 0.70279999999999998)\n",
      "0 (0.67863324802283398, 0.68589999999999995)\n",
      "0 (0.59614196818779197, 0.71660000000000001)\n",
      "0 (0.58842570059874155, 0.75119999999999998)\n",
      "0 (0.57220345385867299, 0.74029999999999996)\n",
      "0 (0.56190765188985781, 0.76970000000000005)\n",
      "0 (0.56369620150013011, 0.74909999999999999)\n",
      "0 (0.56515972422649474, 0.76659999999999995)\n",
      "0 (0.58683677877443441, 0.72330000000000005)\n",
      "0 (0.57174211970415234, 0.76239999999999997)\n",
      "0 (0.55296939052110805, 0.76029999999999998)\n",
      "0 (0.53711906668840015, 0.78139999999999998)\n",
      "0 (0.52945254849798007, 0.78369999999999995)\n",
      "0 (0.5352324606061486, 0.78639999999999999)\n",
      "0 (0.59660842749208509, 0.69879999999999998)\n",
      "0 (0.5218830465054477, 0.77849999999999997)\n",
      "0 (0.50064630665630316, 0.80610000000000004)\n",
      "0 (0.51030525933802007, 0.79930000000000001)\n",
      "0 (0.57219298844957289, 0.71630000000000005)\n",
      "0 (0.49203303907158241, 0.80069999999999997)\n",
      "0 (0.54977990641460694, 0.76970000000000005)\n",
      "0 (0.5032484873805807, 0.81140000000000001)\n",
      "0 (0.5481166654589974, 0.73609999999999998)\n",
      "0 (0.49213181285050062, 0.80730000000000002)\n",
      "0 (0.53657078694811211, 0.76800000000000002)\n",
      "0 (0.43954098185143892, 0.83320000000000005)\n",
      "0 (0.41304351199246775, 0.86360000000000003)\n",
      "0 (0.62210161437109723, 0.60099999999999998)\n",
      "0 (0.66788053161890948, 0.53249999999999997)\n",
      "0 (0.84996949460811266, 0.62070000000000003)\n",
      "0 (0.64162576496185975, 0.63270000000000004)\n",
      "0 (0.52687762927496529, 0.76700000000000002)\n",
      "0 (0.49035523328483177, 0.79200000000000004)\n",
      "0 (0.40900857827097825, 0.85070000000000001)\n",
      "0 (0.4004691623476957, 0.85580000000000001)\n",
      "0 (0.46331835049809494, 0.83699999999999997)\n",
      "0 (0.58154372420539802, 0.68410000000000004)\n",
      "0 (0.40995559513489815, 0.84899999999999998)\n",
      "0 (0.81884125697471632, 0.69789999999999996)\n",
      "0 (0.628010792852564, 0.65200000000000002)\n",
      "0 (0.54937239726870912, 0.72609999999999997)\n",
      "0 (0.4614508331255287, 0.83509999999999995)\n",
      "0 (0.4213267109230035, 0.85489999999999999)\n",
      "0 (0.39289460605319276, 0.8579)\n",
      "0 (0.41511542844689148, 0.83430000000000004)\n",
      "0 (0.63077527988141824, 0.73629999999999995)\n",
      "0 (0.58125262725265547, 0.69740000000000002)\n",
      "0 (0.43186936583437019, 0.85489999999999999)\n",
      "0 (0.40432353102912372, 0.8649)\n",
      "0 (0.3753763646469167, 0.88280000000000003)\n",
      "0 (0.35876124183742697, 0.879)\n",
      "0 (0.45809367387013172, 0.7883)\n",
      "0 (0.41231241894552895, 0.84360000000000002)\n",
      "0 (0.53315125843277122, 0.73089999999999999)\n",
      "0 (0.34592040798030221, 0.89410000000000001)\n",
      "0 (0.35788057213649238, 0.86280000000000001)\n",
      "0 (0.48576928584498985, 0.7621)\n",
      "0 (0.28578738689740463, 0.92169999999999996)\n",
      "1 (0.33447257921933082, 0.87280000000000002)\n",
      "1 (0.95371963083810463, 0.67749999999999999)\n",
      "1 (0.49993790312498876, 0.75660000000000005)\n",
      "1 (0.32475899551068454, 0.91549999999999998)\n",
      "1 (0.31616701006562631, 0.91149999999999998)\n",
      "1 (0.36718197660232366, 0.83809999999999996)\n",
      "1 (0.45925519527379782, 0.78239999999999998)\n",
      "1 (0.28677212585260875, 0.92020000000000002)\n",
      "1 (0.38064701394884759, 0.83530000000000004)\n",
      "1 (0.47462130704325889, 0.80249999999999999)\n",
      "1 (0.47750079994868877, 0.7742)\n",
      "1 (0.28704652605168157, 0.92720000000000002)\n",
      "1 (0.27179571690152504, 0.93149999999999999)\n",
      "1 (0.2624240769002838, 0.93300000000000005)\n",
      "1 (0.40580458365500804, 0.81599999999999995)\n",
      "1 (0.35533925683541395, 0.86409999999999998)\n",
      "1 (0.50247360000984553, 0.75439999999999996)\n",
      "1 (0.29736782874110784, 0.89239999999999997)\n",
      "1 (0.49184002782487385, 0.76329999999999998)\n",
      "1 (0.41509454485149427, 0.81969999999999998)\n",
      "1 (0.33381709308993279, 0.86099999999999999)\n",
      "1 (0.36370700770910025, 0.85270000000000001)\n",
      "1 (0.41520014091972063, 0.80510000000000004)\n",
      "1 (0.38327361216197631, 0.8468)\n",
      "1 (0.3442910051134338, 0.84379999999999999)\n",
      "1 (0.31057558876223068, 0.90639999999999998)\n",
      "1 (0.27278508651157807, 0.91279999999999994)\n",
      "1 (0.27563726548790057, 0.91879999999999995)\n",
      "1 (0.26968634004137104, 0.90059999999999996)\n",
      "1 (0.38412539297641113, 0.83560000000000001)\n",
      "1 (0.34007343823983255, 0.85229999999999995)\n",
      "1 (0.40753272599575024, 0.82569999999999999)\n",
      "1 (0.2923290476953268, 0.87660000000000005)\n",
      "1 (0.29720530808432133, 0.89849999999999997)\n",
      "1 (0.31781917906647639, 0.85299999999999998)\n",
      "1 (0.34098718045041176, 0.86890000000000001)\n",
      "1 (0.33889123921612779, 0.82520000000000004)\n",
      "1 (0.30067035619147825, 0.9093)\n",
      "1 (0.26183679597282672, 0.90039999999999998)\n",
      "1 (0.25433779114068211, 0.92510000000000003)\n",
      "1 (0.26272791537751133, 0.88619999999999999)\n",
      "1 (0.41943262810980558, 0.81899999999999995)\n",
      "1 (0.25602957584631508, 0.88570000000000004)\n",
      "1 (0.32605012244542658, 0.86699999999999999)\n",
      "1 (0.41635554212373482, 0.79669999999999996)\n",
      "1 (0.36379754815281423, 0.86439999999999995)\n",
      "1 (0.33122272827481047, 0.82250000000000001)\n",
      "1 (0.24537121452496705, 0.93279999999999996)\n",
      "1 (0.20409775599107013, 0.93840000000000001)\n",
      "1 (0.18797821911731155, 0.94820000000000004)\n",
      "1 (0.18816695892757496, 0.94059999999999999)\n",
      "1 (0.42081818483296868, 0.81679999999999997)\n",
      "1 (0.25466201335950006, 0.89610000000000001)\n",
      "1 (0.48104034457011141, 0.79179999999999995)\n",
      "1 (0.18583271908665969, 0.96220000000000006)\n",
      "1 (0.17334322700927743, 0.96160000000000001)\n",
      "1 (0.17472624286702965, 0.94199999999999995)\n",
      "1 (0.41026247806394184, 0.81820000000000004)\n",
      "1 (0.23477347136927629, 0.90339999999999998)\n",
      "1 (0.4406265279481032, 0.80840000000000001)\n",
      "1 (0.18560097008596133, 0.94230000000000003)\n",
      "1 (0.28398590132477675, 0.88129999999999997)\n",
      "1 (0.64202882036800191, 0.7742)\n",
      "1 (0.3065761453591298, 0.87929999999999997)\n",
      "1 (0.33259563595466962, 0.80730000000000002)\n",
      "1 (0.23172622693744188, 0.94720000000000004)\n",
      "1 (0.20146300381470683, 0.96189999999999998)\n",
      "1 (0.20854798425743729, 0.93640000000000001)\n",
      "1 (0.29990584941835058, 0.84030000000000005)\n",
      "1 (0.35917044532259496, 0.86150000000000004)\n",
      "1 (0.28072331882921669, 0.83750000000000002)\n",
      "1 (0.21148240252553482, 0.95099999999999996)\n",
      "1 (0.20191208572724564, 0.91879999999999995)\n",
      "1 (0.21246289025878795, 0.92879999999999996)\n",
      "1 (0.45163182695088611, 0.80220000000000002)\n",
      "1 (0.34025223178922487, 0.87270000000000003)\n",
      "1 (0.29558417392916014, 0.81589999999999996)\n",
      "1 (0.2267292554013508, 0.95369999999999999)\n",
      "1 (0.19584318264700254, 0.96409999999999996)\n",
      "2 (0.20297462705545372, 0.94120000000000004)\n",
      "2 (0.2553183734110952, 0.85199999999999998)\n",
      "2 (0.25283291810567532, 0.91500000000000004)\n",
      "2 (0.35289461992713839, 0.78539999999999999)\n",
      "2 (0.2343034019361406, 0.94489999999999996)\n",
      "2 (0.25245695863743228, 0.88190000000000002)\n",
      "2 (0.18033035324550378, 0.97119999999999995)\n",
      "2 (0.16770593708004464, 0.95630000000000004)\n",
      "2 (0.28590668947668341, 0.89029999999999998)\n",
      "2 (0.51386954818054442, 0.7732)\n",
      "2 (0.22638183579085552, 0.93079999999999996)\n",
      "2 (0.29263727264584288, 0.81259999999999999)\n",
      "2 (0.18725641906287446, 0.97109999999999996)\n",
      "2 (0.16248547976306207, 0.9788)\n",
      "2 (0.14541635150692009, 0.97840000000000005)\n",
      "2 (0.17108679237062613, 0.92210000000000003)\n",
      "2 (0.22706873568076422, 0.91649999999999998)\n",
      "2 (0.79914485603541674, 0.72719999999999996)\n",
      "2 (0.15467199522838793, 0.9778)\n",
      "2 (0.16348886703471696, 0.94430000000000003)\n",
      "2 (0.26411090618899774, 0.90439999999999998)\n",
      "2 (0.522734079724403, 0.75800000000000001)\n",
      "2 (0.18310417949192584, 0.96079999999999999)\n",
      "2 (0.22346393966404643, 0.877)\n",
      "2 (0.16621471972683399, 0.96319999999999995)\n",
      "2 (0.22384648962921333, 0.86399999999999999)\n",
      "2 (0.19319837550597227, 0.94469999999999998)\n",
      "2 (0.38870302228196513, 0.77680000000000005)\n",
      "2 (0.18852123418847774, 0.96650000000000003)\n",
      "2 (0.20079595448230494, 0.91449999999999998)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 (0.17953560025215379, 0.95569999999999999)\n",
      "2 (0.26675874316220222, 0.82940000000000003)\n",
      "2 (0.19099862587404304, 0.95369999999999999)\n",
      "2 (0.26869174284335634, 0.81969999999999998)\n",
      "2 (0.17568917132242784, 0.96809999999999996)\n",
      "2 (0.19516008936673607, 0.89449999999999996)\n",
      "2 (0.14725491807292207, 0.97319999999999995)\n",
      "2 (0.1924936948338371, 0.87609999999999999)\n",
      "2 (0.21369256145893059, 0.93369999999999997)\n",
      "2 (0.69273820762646665, 0.71919999999999995)\n",
      "2 (0.17084215159514671, 0.97629999999999995)\n",
      "2 (0.2710143026960472, 0.91490000000000005)\n",
      "2 (0.38081558869183435, 0.76839999999999997)\n",
      "2 (0.18331191960906695, 0.97760000000000002)\n",
      "2 (0.1579073604871076, 0.97860000000000003)\n",
      "2 (0.14130721802195145, 0.97860000000000003)\n",
      "2 (0.31532647194751429, 0.88919999999999999)\n",
      "2 (0.39103356664180966, 0.78100000000000003)\n",
      "2 (0.15084314836626997, 0.97660000000000002)\n",
      "2 (0.16241993239384914, 0.94440000000000002)\n",
      "2 (0.23406342950303438, 0.92000000000000004)\n",
      "2 (0.47444217225841812, 0.75700000000000001)\n",
      "2 (0.15311415736822984, 0.97389999999999999)\n",
      "2 (0.22632389877297807, 0.92749999999999999)\n",
      "2 (0.37741948428745892, 0.77649999999999997)\n",
      "2 (0.16579673569186279, 0.9698)\n",
      "2 (0.20446639238568229, 0.9415)\n",
      "2 (0.30079925182469941, 0.80600000000000005)\n",
      "2 (0.15565822056438469, 0.97660000000000002)\n",
      "2 (0.19830221527947173, 0.94269999999999998)\n",
      "2 (0.33151989857508152, 0.78779999999999994)\n",
      "2 (0.15532300992150877, 0.98080000000000001)\n",
      "2 (0.19396363504829164, 0.94540000000000002)\n",
      "2 (0.31388197947415503, 0.79400000000000004)\n",
      "2 (0.15392394750966806, 0.97909999999999997)\n",
      "2 (0.25154313854114452, 0.92010000000000003)\n",
      "2 (0.33969388501236614, 0.78249999999999997)\n",
      "2 (0.16966727184595465, 0.96040000000000003)\n",
      "2 (0.22221163174454445, 0.93359999999999999)\n",
      "2 (0.29251128094601619, 0.80330000000000001)\n",
      "2 (0.16421132070511726, 0.96089999999999998)\n",
      "2 (0.20893829998667224, 0.93930000000000002)\n",
      "2 (0.27456354179401965, 0.81310000000000004)\n",
      "2 (0.15756734370359904, 0.96050000000000002)\n",
      "2 (0.19754124249295546, 0.94320000000000004)\n",
      "2 (0.26193967821689662, 0.81989999999999996)\n",
      "2 (0.1430654215674467, 0.97870000000000001)\n",
      "2 (0.1433580371710835, 0.97019999999999995)\n",
      "2 (0.16583031732563672, 0.90390000000000004)\n",
      "3 (0.11382160514316801, 0.97919999999999996)\n",
      "3 (0.11733224648044852, 0.95179999999999998)\n",
      "3 (0.20349978158261764, 0.92789999999999995)\n",
      "3 (0.69911482028762251, 0.76680000000000004)\n",
      "3 (0.11930249513812213, 0.95920000000000005)\n",
      "3 (0.1804725563712081, 0.94020000000000004)\n",
      "3 (0.42712369535621802, 0.80159999999999998)\n",
      "3 (0.12078288844534836, 0.98119999999999996)\n",
      "3 (0.10724603860122971, 0.98380000000000001)\n",
      "3 (0.099008752022799129, 0.98450000000000004)\n",
      "3 (0.091000093674543536, 0.98280000000000001)\n",
      "3 (0.2537146317534561, 0.9103)\n",
      "3 (0.55451130085482636, 0.78420000000000001)\n",
      "3 (0.10273370958717479, 0.97940000000000005)\n",
      "3 (0.24537297386826434, 0.91469999999999996)\n",
      "3 (0.40730876396203036, 0.79859999999999998)\n",
      "3 (0.11409679645621378, 0.98099999999999998)\n",
      "3 (0.12019226897977488, 0.97299999999999998)\n",
      "3 (0.16544742470210658, 0.90739999999999998)\n",
      "3 (0.095997795094790714, 0.98529999999999995)\n",
      "3 (0.085519693998717963, 0.98850000000000005)\n",
      "3 (0.087898889828713869, 0.98229999999999995)\n",
      "3 (0.15669050716956737, 0.90639999999999998)\n",
      "3 (0.11092828214042606, 0.96740000000000004)\n",
      "3 (0.42091747784858291, 0.80479999999999996)\n",
      "3 (0.094721664694095584, 0.98609999999999998)\n",
      "3 (0.14962174919129917, 0.91320000000000001)\n",
      "3 (0.11075873730023993, 0.97250000000000003)\n",
      "3 (0.31518328314269539, 0.82050000000000001)\n",
      "3 (0.10638950125376125, 0.9849)\n",
      "3 (0.16802146494903986, 0.88970000000000005)\n",
      "3 (0.091681000329675674, 0.99360000000000004)\n",
      "3 (0.20339717497397214, 0.93700000000000006)\n",
      "3 (0.58152027456649735, 0.74870000000000003)\n",
      "3 (0.152028219978906, 0.92169999999999996)\n",
      "3 (0.10952736018311932, 0.98860000000000003)\n",
      "3 (0.124145264295294, 0.9456)\n",
      "3 (0.16851716496330926, 0.95289999999999997)\n",
      "3 (0.49511464170384323, 0.76500000000000001)\n",
      "3 (0.14391917528981693, 0.93379999999999996)\n",
      "3 (0.13998709989381444, 0.96989999999999998)\n",
      "3 (0.24348290366297209, 0.83389999999999997)\n",
      "3 (0.11957984017944009, 0.98880000000000001)\n",
      "3 (0.10479670317476132, 0.99019999999999997)\n",
      "3 (0.095544352301632857, 0.98829999999999996)\n",
      "3 (0.22225536730181816, 0.93020000000000003)\n",
      "3 (0.53245416779319399, 0.76049999999999995)\n",
      "3 (0.15390239643571854, 0.91320000000000001)\n",
      "3 (0.10121749942666347, 0.99070000000000003)\n",
      "3 (0.13538604664538603, 0.96550000000000002)\n",
      "3 (0.29043704201126269, 0.82289999999999996)\n",
      "3 (0.10727395131424891, 0.99009999999999998)\n",
      "3 (0.15912467605656794, 0.95689999999999997)\n",
      "3 (0.30464722190994326, 0.81369999999999998)\n",
      "3 (0.12340496262279953, 0.9748)\n",
      "3 (0.23717836423644667, 0.92679999999999996)\n",
      "3 (0.3738282747688092, 0.7843)\n",
      "3 (0.15713424251510147, 0.93820000000000003)\n",
      "3 (0.14605533960474459, 0.9718)\n",
      "3 (0.16092037479696442, 0.90480000000000005)\n",
      "3 (0.10981750021393338, 0.9788)\n",
      "3 (0.21683509940207837, 0.93340000000000001)\n",
      "3 (0.36534594063172537, 0.80020000000000002)\n",
      "3 (0.13182791670949445, 0.95879999999999999)\n",
      "3 (0.15071469579878469, 0.96220000000000006)\n",
      "3 (0.17693279652688357, 0.88239999999999996)\n",
      "3 (0.10784119028783627, 0.98140000000000005)\n",
      "3 (0.10435031440535676, 0.98080000000000001)\n",
      "3 (0.10405431367437361, 0.96430000000000005)\n",
      "3 (0.20181822059757701, 0.93389999999999995)\n",
      "3 (0.43941816147192875, 0.79700000000000004)\n",
      "3 (0.11747203395396125, 0.95299999999999996)\n",
      "3 (0.13576635303548368, 0.96240000000000003)\n",
      "3 (0.19073251702680782, 0.87290000000000001)\n",
      "3 (0.097085364558323159, 0.98560000000000003)\n",
      "3 (0.09395167998547295, 0.98460000000000003)\n",
      "3 (0.097220497704885278, 0.96440000000000003)\n",
      "3 (0.22103564908909115, 0.92769999999999997)\n",
      "3 (0.53333017270315441, 0.78129999999999999)\n",
      "4 (0.12315806093203675, 0.93020000000000003)\n",
      "4 (0.092253299728644364, 0.98529999999999995)\n",
      "4 (0.085319791680347118, 0.97860000000000003)\n",
      "4 (0.19973971577878327, 0.9345)\n",
      "4 (0.44203508167220107, 0.80189999999999995)\n",
      "4 (0.10729834340284551, 0.95269999999999999)\n",
      "4 (0.11285826364464176, 0.9718)\n",
      "4 (0.16730391256486413, 0.88329999999999997)\n",
      "4 (0.088944926901523086, 0.98939999999999995)\n",
      "4 (0.079009698749207435, 0.9929)\n",
      "4 (0.13019459372645195, 0.96160000000000001)\n",
      "4 (0.31223520757870649, 0.83479999999999999)\n",
      "4 (0.088763555154087015, 0.98319999999999996)\n",
      "4 (0.16758336415952066, 0.94889999999999997)\n",
      "4 (0.38568637895438646, 0.80730000000000002)\n",
      "4 (0.1073284343384371, 0.96640000000000004)\n",
      "4 (0.15833071282747288, 0.95420000000000005)\n",
      "4 (0.25720700162668297, 0.84050000000000002)\n",
      "4 (0.10845372488677528, 0.97689999999999999)\n",
      "4 (0.14983414174936646, 0.95989999999999998)\n",
      "4 (0.21270373553098257, 0.85509999999999997)\n",
      "4 (0.11111036866461454, 0.97409999999999997)\n",
      "4 (0.15719682804476576, 0.95720000000000005)\n",
      "4 (0.2044593003782077, 0.85870000000000002)\n",
      "4 (0.11204309030012516, 0.9708)\n",
      "4 (0.13654618306122096, 0.96640000000000004)\n",
      "4 (0.15836084727479838, 0.88439999999999996)\n",
      "4 (0.095566825680173106, 0.98650000000000004)\n",
      "4 (0.15098374523658359, 0.95679999999999998)\n",
      "4 (0.23934353881291359, 0.84819999999999995)\n",
      "4 (0.099647169716127956, 0.98129999999999995)\n",
      "4 (0.16259470659407299, 0.95250000000000001)\n",
      "4 (0.25018196662386438, 0.84370000000000001)\n",
      "4 (0.10517856409793565, 0.97589999999999999)\n",
      "4 (0.13677777946591174, 0.96509999999999996)\n",
      "4 (0.16829880715668522, 0.87609999999999999)\n",
      "4 (0.09518654166338511, 0.98350000000000004)\n",
      "4 (0.130668192403322, 0.96519999999999995)\n",
      "4 (0.18951115506755312, 0.86780000000000002)\n",
      "4 (0.090939481163404279, 0.99199999999999999)\n",
      "4 (0.12616469542885247, 0.9657)\n",
      "4 (0.18790427688165198, 0.86809999999999998)\n",
      "4 (0.089181703162230411, 0.99299999999999999)\n",
      "4 (0.10688606891165396, 0.97370000000000001)\n",
      "4 (0.15366983772145545, 0.8851)\n",
      "4 (0.081735925681593394, 0.99080000000000001)\n",
      "4 (0.16241179517617466, 0.95040000000000002)\n",
      "4 (0.39202350962893234, 0.81540000000000001)\n",
      "4 (0.10789995713368296, 0.95650000000000002)\n",
      "4 (0.10597161363968539, 0.97709999999999997)\n",
      "4 (0.1343048665020895, 0.90039999999999998)\n",
      "4 (0.080919628314639641, 0.9919)\n",
      "4 (0.13274504008613935, 0.96209999999999996)\n",
      "4 (0.2696872260644958, 0.84179999999999999)\n",
      "4 (0.094690723952920774, 0.97689999999999999)\n",
      "4 (0.15189644652791007, 0.95660000000000001)\n",
      "4 (0.25515043670614396, 0.84219999999999995)\n",
      "4 (0.10595684670075084, 0.96640000000000004)\n",
      "4 (0.12964149498942806, 0.96760000000000002)\n",
      "4 (0.15242600770485629, 0.88700000000000001)\n",
      "4 (0.09262182136627066, 0.98140000000000005)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 (0.13950017430121053, 0.96109999999999995)\n",
      "4 (0.22603507924362967, 0.85329999999999995)\n",
      "4 (0.094569484363566964, 0.98429999999999995)\n",
      "4 (0.14066532514981148, 0.96140000000000003)\n",
      "4 (0.20942723166175034, 0.85729999999999995)\n",
      "4 (0.1007326829126847, 0.97470000000000001)\n",
      "4 (0.14155788701708852, 0.96220000000000006)\n",
      "4 (0.19242304863062829, 0.86360000000000003)\n",
      "4 (0.10087558919554904, 0.97509999999999997)\n",
      "4 (0.1375939515329134, 0.96430000000000005)\n",
      "4 (0.1851402402794412, 0.86629999999999996)\n",
      "4 (0.098059580540327859, 0.97899999999999998)\n",
      "4 (0.1402968950407418, 0.96240000000000003)\n",
      "4 (0.19608748772208923, 0.86150000000000004)\n",
      "4 (0.097883512685565111, 0.97989999999999999)\n",
      "4 (0.13478355970940276, 0.96530000000000005)\n",
      "4 (0.17313512486659161, 0.87170000000000003)\n",
      "4 (0.10033505993984437, 0.96719999999999995)\n",
      "5 (0.13791837836939563, 0.96240000000000003)\n",
      "5 (0.174543265810265, 0.87050000000000005)\n",
      "5 (0.096714997419278137, 0.97250000000000003)\n",
      "5 (0.11576742497188409, 0.97099999999999997)\n",
      "5 (0.12969662533939177, 0.89729999999999999)\n",
      "5 (0.083909939613446741, 0.97809999999999997)\n",
      "5 (0.12408624862523691, 0.96479999999999999)\n",
      "5 (0.19998108360018796, 0.86929999999999996)\n",
      "5 (0.082762847824354988, 0.99239999999999995)\n",
      "5 (0.089093959419970017, 0.98309999999999997)\n",
      "5 (0.096694211366103386, 0.93520000000000003)\n",
      "5 (0.064607607394885969, 0.99209999999999998)\n",
      "5 (0.1202195634018116, 0.96260000000000001)\n",
      "5 (0.35823909686746713, 0.84319999999999995)\n",
      "5 (0.083471063725185174, 0.96809999999999996)\n",
      "5 (0.11230443484747575, 0.96740000000000004)\n",
      "5 (0.17352079370616555, 0.88219999999999998)\n",
      "5 (0.077682187039537193, 0.99070000000000003)\n",
      "5 (0.070846866025551319, 0.99170000000000003)\n",
      "5 (0.067160359154682006, 0.98570000000000002)\n",
      "5 (0.13053234367228883, 0.96009999999999995)\n",
      "5 (0.33834619052132636, 0.84150000000000003)\n",
      "5 (0.085403732566426999, 0.96479999999999999)\n",
      "5 (0.10673504144646652, 0.96930000000000005)\n",
      "5 (0.17138361223589849, 0.88)\n",
      "5 (0.075499223800512077, 0.9899)\n",
      "5 (0.12169884013272601, 0.96409999999999996)\n",
      "5 (0.21344692065872367, 0.86219999999999997)\n",
      "5 (0.083806055303017296, 0.9829)\n",
      "5 (0.1238608759320005, 0.96479999999999999)\n",
      "5 (0.17867549070984287, 0.87309999999999999)\n",
      "5 (0.089775216265492244, 0.97489999999999999)\n",
      "5 (0.13536902001448856, 0.96179999999999999)\n",
      "5 (0.19840584499650665, 0.8639)\n",
      "5 (0.094883842015420286, 0.97319999999999995)\n",
      "5 (0.13454500891077756, 0.96399999999999997)\n",
      "5 (0.16771513096404811, 0.87439999999999996)\n",
      "5 (0.10037985956458066, 0.96189999999999998)\n",
      "5 (0.100105403732017, 0.97989999999999999)\n",
      "5 (0.10976132534497231, 0.92479999999999996)\n",
      "5 (0.078828718733310946, 0.98209999999999997)\n",
      "5 (0.10879130228129506, 0.97030000000000005)\n",
      "5 (0.19366243663893268, 0.87139999999999995)\n",
      "5 (0.084050482429356296, 0.98180000000000001)\n",
      "5 (0.11311040540487018, 0.96870000000000001)\n",
      "5 (0.15999068618340809, 0.88290000000000002)\n",
      "5 (0.081633055028534143, 0.98250000000000004)\n",
      "5 (0.11300720910795621, 0.96899999999999997)\n",
      "5 (0.1546928734265364, 0.88270000000000004)\n",
      "5 (0.079762079489574936, 0.98219999999999996)\n",
      "5 (0.13805649414533697, 0.96050000000000002)\n",
      "5 (0.25628846347929968, 0.84830000000000005)\n",
      "5 (0.091602103806493931, 0.97299999999999998)\n",
      "5 (0.1347404950392099, 0.96399999999999997)\n",
      "5 (0.16859739981277116, 0.87370000000000003)\n",
      "5 (0.093235916706595146, 0.97240000000000004)\n",
      "5 (0.13190960215231656, 0.96460000000000001)\n",
      "5 (0.16217762539227998, 0.87649999999999995)\n",
      "5 (0.091131543209464441, 0.97709999999999997)\n",
      "5 (0.1226847486649858, 0.96750000000000003)\n",
      "5 (0.14330996336486201, 0.88649999999999995)\n",
      "5 (0.090620673278315231, 0.97019999999999995)\n",
      "5 (0.11009738176733233, 0.97189999999999999)\n",
      "5 (0.13443825984548288, 0.89049999999999996)\n",
      "5 (0.083507985353226608, 0.97750000000000004)\n",
      "5 (0.1267031630257297, 0.96430000000000005)\n",
      "5 (0.21247809058510433, 0.86009999999999998)\n",
      "5 (0.089537606500729186, 0.97070000000000001)\n",
      "5 (0.13551031990914075, 0.96260000000000001)\n",
      "5 (0.18493869738455082, 0.87)\n",
      "5 (0.091377681352336301, 0.97309999999999997)\n",
      "5 (0.11230400541916508, 0.97219999999999995)\n",
      "5 (0.13551849742647942, 0.88839999999999997)\n",
      "5 (0.09074537550481207, 0.96579999999999999)\n",
      "5 (0.092256303466340825, 0.98350000000000004)\n",
      "5 (0.091164364661258851, 0.9385)\n",
      "5 (0.067284257433689668, 0.99009999999999998)\n",
      "5 (0.10241373681293417, 0.97109999999999996)\n",
      "5 (0.24211565841755472, 0.86480000000000001)\n",
      "6 (0.073690753352288571, 0.98380000000000001)\n",
      "6 (0.098197284323184239, 0.9748)\n",
      "6 (0.14993758435788554, 0.88919999999999999)\n",
      "6 (0.078140516728967754, 0.97860000000000003)\n",
      "6 (0.10037453304141697, 0.97419999999999995)\n",
      "6 (0.13131209930429308, 0.89790000000000003)\n",
      "6 (0.073945488091625419, 0.98550000000000004)\n",
      "6 (0.096031713475911606, 0.97589999999999999)\n",
      "6 (0.12834784113288522, 0.9022)\n",
      "6 (0.074840650665841307, 0.98350000000000004)\n",
      "6 (0.097599781691012868, 0.9748)\n",
      "6 (0.1372674971177355, 0.89590000000000003)\n",
      "6 (0.071237976478205026, 0.9869)\n",
      "6 (0.09660667449521966, 0.97489999999999999)\n",
      "6 (0.13847336461524443, 0.89459999999999995)\n",
      "6 (0.070427199995959061, 0.98999999999999999)\n",
      "6 (0.10772546965057035, 0.96999999999999997)\n",
      "6 (0.1755963275146698, 0.87880000000000003)\n",
      "6 (0.075956466892386942, 0.98319999999999996)\n",
      "6 (0.10547412053850076, 0.97109999999999996)\n",
      "6 (0.13977851930224242, 0.89049999999999996)\n",
      "6 (0.077234730333334667, 0.97970000000000002)\n",
      "6 (0.10344861893160326, 0.97209999999999996)\n",
      "6 (0.13922262021760051, 0.89059999999999995)\n",
      "6 (0.079013505503429449, 0.97650000000000003)\n",
      "6 (0.10696967092765854, 0.97109999999999996)\n",
      "6 (0.14316554477112298, 0.88829999999999998)\n",
      "6 (0.079801385207196013, 0.97609999999999997)\n",
      "6 (0.11206453017404354, 0.96919999999999995)\n",
      "6 (0.14594967630625588, 0.88660000000000005)\n",
      "6 (0.078751829419887578, 0.97999999999999998)\n",
      "6 (0.099676353490211589, 0.97460000000000002)\n",
      "6 (0.11293524479199514, 0.90500000000000003)\n",
      "6 (0.072954705483137428, 0.98280000000000001)\n",
      "6 (0.11043084651963882, 0.96970000000000001)\n",
      "6 (0.19103139080285664, 0.87090000000000001)\n",
      "6 (0.081194836180102217, 0.97189999999999999)\n",
      "6 (0.088680606848538429, 0.98160000000000003)\n",
      "6 (0.091202181328606927, 0.92769999999999997)\n",
      "6 (0.067317097924716796, 0.98309999999999997)\n",
      "6 (0.12314216298616876, 0.96360000000000001)\n",
      "6 (0.31962646820934915, 0.84540000000000004)\n",
      "6 (0.082866745556223559, 0.95199999999999996)\n",
      "6 (0.065295910074761418, 0.99570000000000003)\n",
      "6 (0.06786919090480481, 0.98939999999999995)\n",
      "6 (0.072619306173283285, 0.95340000000000003)\n",
      "6 (0.054301513402700695, 0.99490000000000001)\n",
      "6 (0.049793431906744706, 0.99109999999999998)\n",
      "6 (0.093467153379230741, 0.97160000000000002)\n",
      "6 (0.38454065420840811, 0.84830000000000005)\n",
      "6 (0.070306204981436748, 0.95120000000000005)\n",
      "6 (0.055506299963458787, 0.99109999999999998)\n",
      "6 (0.062885269576850159, 0.95899999999999996)\n",
      "6 (0.077493419146204764, 0.97740000000000005)\n",
      "6 (0.25226192061053759, 0.87639999999999996)\n",
      "6 (0.054264259544424931, 0.98299999999999998)\n",
      "6 (0.10048535232043003, 0.96940000000000004)\n",
      "6 (0.35481428316325564, 0.85009999999999997)\n",
      "6 (0.069878095763685297, 0.95409999999999995)\n",
      "6 (0.054493339440716194, 0.99550000000000005)\n",
      "6 (0.052522069052606216, 0.99450000000000005)\n",
      "6 (0.05006580169228117, 0.98570000000000002)\n",
      "6 (0.0969841773264387, 0.96989999999999998)\n",
      "6 (0.3871513613836946, 0.84889999999999999)\n",
      "6 (0.072084498197882152, 0.94499999999999995)\n",
      "6 (0.052767259442930162, 0.99490000000000001)\n",
      "6 (0.048018530491525359, 0.99480000000000002)\n",
      "6 (0.095131079517405945, 0.97060000000000002)\n",
      "6 (0.36599415359258608, 0.85229999999999995)\n",
      "6 (0.06931500738403118, 0.94989999999999997)\n",
      "6 (0.06252519349386039, 0.98819999999999997)\n",
      "6 (0.069554826895052241, 0.94699999999999995)\n",
      "6 (0.057465536949911619, 0.98999999999999999)\n",
      "6 (0.064568701038089121, 0.95230000000000004)\n",
      "6 (0.061313957289112646, 0.98709999999999998)\n",
      "6 (0.082159052574140259, 0.93410000000000004)\n",
      "6 (0.056630330605186671, 0.9899)\n",
      "6 (0.074587557858040873, 0.93910000000000005)\n",
      "6 (0.059460494557930267, 0.98829999999999996)\n",
      "6 (0.059460494557930267, 0.98829999999999996)\n"
     ]
    }
   ],
   "source": [
    "nn = DeepLearning(X,y,learning_rate=0.5)\n",
    "nn.add_layer(3,acti_fn='relu')\n",
    "nn.add_layer(7,acti_fn='relu')\n",
    "nn.add_layer(5,acti_fn='relu')\n",
    "nn.add_layer(9,acti_fn='relu')\n",
    "nn.add_layer(6,acti_fn='relu')\n",
    "nn.add_layer(9,acti_fn='relu')\n",
    "nn.add_layer(5,acti_fn='relu')\n",
    "nn.add_layer(7,acti_fn='relu')\n",
    "nn.add_layer(3,acti_fn='relu')\n",
    "nn.add_layer(1)\n",
    "\n",
    "nn.batch_train(optimization_algo='momentum',momentum_beta=0.9,batch_size=128,decay=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
